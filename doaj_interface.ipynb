{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Journals which we are searching for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   title      eiisn           category  \\\n",
      "0                     Biomedical Journal  2320-2890           Medicine   \n",
      "1  African Journal of Emergency Medicine  2211-4203           Medicine   \n",
      "2          Ain Shams Engineering Journal  2090-4495  Civil Engineering   \n",
      "3         Alexandria Engineering Journal  2090-2670  Civil Engineering   \n",
      "4      Anais Brasileiros de Dermatologia  1806-4841           Medicine   \n",
      "\n",
      "                              publisher      eissn      pissn  \\\n",
      "0                              Elsevier  2320-2890  2319-4170   \n",
      "1                              Elsevier  2211-419X        NaN   \n",
      "2                              Elsevier        NaN  2090-4479   \n",
      "3                              Elsevier        NaN  1110-0168   \n",
      "4  Sociedade Brasileira de Dermatologia        NaN  0365-0596   \n",
      "\n",
      "                             doajid  \\\n",
      "0  d1e768538ffa4f82826f04f163a7fa38   \n",
      "1  8150ee089d8b4f099f6c30bd8aaf0fcc   \n",
      "2  5622b8878c204fd2b88130fbeea2f2d7   \n",
      "3  40ae382df340487c8266f817e3a03683   \n",
      "4  bbbc2abf7b4a4a74a81784b75472ca54   \n",
      "\n",
      "                                          categories language  \n",
      "0               Medicine (General)#Biology (General)       EN  \n",
      "1                        Medicine#Medicine (General)       EN  \n",
      "2  Engineering (General). Civil engineering (Gene...       EN  \n",
      "3  Engineering (General). Civil engineering (Gene...       EN  \n",
      "4                                        Dermatology    EN#PT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "journals = pd.read_csv('doaj_journals.csv', sep=\"|\")\n",
    "print(journals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the article details from DOAJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findjournaldata(results):\n",
    "    publisher = None\n",
    "    eissn = None\n",
    "    pissn = None\n",
    "    title = None\n",
    "    doajid = None\n",
    "    categories = None\n",
    "    language = None\n",
    "    notfound = True\n",
    "    # iterate over the result and try to find where title exactly match\n",
    "    for result in results:\n",
    "            if result['bibjson']['title'].lower().strip() == journals.iloc[idx]['title'].lower().strip():\n",
    "                notfound = False\n",
    "                publisher = result['bibjson']['publisher']['name'] \n",
    "                if 'eissn' in result['bibjson'].keys():\n",
    "                    eissn = result['bibjson']['eissn'] \n",
    "                if 'pissn' in result['bibjson'].keys():\n",
    "                    pissn = result['bibjson']['pissn'] \n",
    "\n",
    "                title = result['bibjson']['title'] \n",
    "                doajid = result['id'] \n",
    "                categories =  \"#\".join(  [ s['term'].strip() for s in result['bibjson']['subject'] ] ) \n",
    "                language = \"#\".join(  [ s.strip() for s in result['bibjson']['language'] ] ) \n",
    "                \n",
    "                break\n",
    "    return notfound, publisher, eissn, pissn, title, doajid, categories, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "from time import sleep\n",
    "\n",
    "publishers = []\n",
    "eissns = []\n",
    "pissns = []\n",
    "titles = []\n",
    "doajids = []\n",
    "categoriess = []\n",
    "languages = []\n",
    "for idx in range(len(journals)):\n",
    "    if 'doajid' not in journals.columns or journals.iloc[idx]['doajid'] is None:\n",
    "        searchterm = urllib.parse.quote('bibjson.title:\"'+journals.iloc[idx]['title']+'\"')\n",
    "        searchterm = 'https://doaj.org/api/v2/search/journals/'+searchterm\n",
    "        x = requests.get(searchterm)\n",
    "        notfound = True\n",
    "        if x.status_code == 200:\n",
    "            # iterate over pages\n",
    "            jsonresult =  x.json()\n",
    "            if 'total' in jsonresult.keys() :\n",
    "                for page in range(int(jsonresult['total'])):\n",
    "                    page = page+1\n",
    "                    if 'results' in jsonresult.keys():                \n",
    "                        notfound, publisher, eissn, pissn, title, doajid, categories, language = findjournaldata(jsonresult['results'])\n",
    "                        if not notfound:\n",
    "                            publishers.append(publisher)\n",
    "                            eissns.append(eissn)\n",
    "                            pissns.append(pissn)\n",
    "                            titles.append(title)\n",
    "                            doajids.append(doajid)\n",
    "                            categoriess.append(categories)\n",
    "                            languages.append(language)\n",
    "                            break\n",
    "                        else:\n",
    "                            if jsonresult['total'] > 1:\n",
    "                                # go to next page\n",
    "                                x = requests.get(searchterm+\"?page=\"+str(page)+\"&pageSize=10\")\n",
    "                                print(searchterm+\"?page=\"+str(page)+\"&pageSize=10\")\n",
    "                                if x.status_code == 200:\n",
    "                                    jsonresult =  x.json()\n",
    "                                else:\n",
    "                                    break\n",
    "                \n",
    "       \n",
    "        if notfound:\n",
    "            # test there is new page if yes go there        \n",
    "            print(\"Error:\", searchterm)\n",
    "            publishers.append(None)\n",
    "            eissns.append(None)\n",
    "            pissns.append(None)\n",
    "            titles.append(None)\n",
    "            doajids.append(None)\n",
    "            categoriess.append(None)\n",
    "            languages.append(None)\n",
    "        sleep(3)\n",
    "    else:\n",
    "        publishers.append(journals.iloc[idx]['publisher'])\n",
    "        eissns.append(journals.iloc[idx]['eissn'])\n",
    "        pissns.append(journals.iloc[idx]['pissn'])\n",
    "        titles.append(journals.iloc[idx]['title'])\n",
    "        doajids.append(journals.iloc[idx]['doajid'])\n",
    "        categoriess.append(journals.iloc[idx]['categories'])\n",
    "        languages.append(journals.iloc[idx]['language'])\n",
    "    \n",
    "# enrich journals\n",
    "journals['publisher'] = publishers\n",
    "journals['eissn'] = eissns\n",
    "journals['pissn'] = pissns\n",
    "journals['title'] = titles\n",
    "journals['doajid'] = doajids\n",
    "journals['categories'] = categoriess\n",
    "journals['language'] = languages\n",
    "\n",
    "journals.to_csv('doaj_journals.csv', sep=\"|\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>eiisn</th>\n",
       "      <th>category</th>\n",
       "      <th>publisher</th>\n",
       "      <th>eissn</th>\n",
       "      <th>pissn</th>\n",
       "      <th>doajid</th>\n",
       "      <th>categories</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biomedical Journal</td>\n",
       "      <td>2320-2890</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>2320-2890</td>\n",
       "      <td>2319-4170</td>\n",
       "      <td>d1e768538ffa4f82826f04f163a7fa38</td>\n",
       "      <td>Medicine (General)#Biology (General)</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African Journal of Emergency Medicine</td>\n",
       "      <td>2211-4203</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>2211-419X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8150ee089d8b4f099f6c30bd8aaf0fcc</td>\n",
       "      <td>Medicine#Medicine (General)</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ain Shams Engineering Journal</td>\n",
       "      <td>2090-4495</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2090-4479</td>\n",
       "      <td>5622b8878c204fd2b88130fbeea2f2d7</td>\n",
       "      <td>Engineering (General). Civil engineering (Gene...</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexandria Engineering Journal</td>\n",
       "      <td>2090-2670</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110-0168</td>\n",
       "      <td>40ae382df340487c8266f817e3a03683</td>\n",
       "      <td>Engineering (General). Civil engineering (Gene...</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anais Brasileiros de Dermatologia</td>\n",
       "      <td>1806-4841</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Sociedade Brasileira de Dermatologia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0365-0596</td>\n",
       "      <td>bbbc2abf7b4a4a74a81784b75472ca54</td>\n",
       "      <td>Dermatology</td>\n",
       "      <td>EN#PT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title      eiisn           category  \\\n",
       "0                     Biomedical Journal  2320-2890           Medicine   \n",
       "1  African Journal of Emergency Medicine  2211-4203           Medicine   \n",
       "2          Ain Shams Engineering Journal  2090-4495  Civil Engineering   \n",
       "3         Alexandria Engineering Journal  2090-2670  Civil Engineering   \n",
       "4      Anais Brasileiros de Dermatologia  1806-4841           Medicine   \n",
       "\n",
       "                              publisher      eissn      pissn  \\\n",
       "0                              Elsevier  2320-2890  2319-4170   \n",
       "1                              Elsevier  2211-419X        NaN   \n",
       "2                              Elsevier        NaN  2090-4479   \n",
       "3                              Elsevier        NaN  1110-0168   \n",
       "4  Sociedade Brasileira de Dermatologia        NaN  0365-0596   \n",
       "\n",
       "                             doajid  \\\n",
       "0  d1e768538ffa4f82826f04f163a7fa38   \n",
       "1  8150ee089d8b4f099f6c30bd8aaf0fcc   \n",
       "2  5622b8878c204fd2b88130fbeea2f2d7   \n",
       "3  40ae382df340487c8266f817e3a03683   \n",
       "4  bbbc2abf7b4a4a74a81784b75472ca54   \n",
       "\n",
       "                                          categories language  \n",
       "0               Medicine (General)#Biology (General)       EN  \n",
       "1                        Medicine#Medicine (General)       EN  \n",
       "2  Engineering (General). Civil engineering (Gene...       EN  \n",
       "3  Engineering (General). Civil engineering (Gene...       EN  \n",
       "4                                        Dermatology    EN#PT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "journals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the articles for the Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findarticledata(results):\n",
    "    \n",
    "    # iterrate over Articles\n",
    "    url = []\n",
    "    title = []\n",
    "    doi = []\n",
    "    abstract  = []\n",
    "    writers = []\n",
    "    publishdate = []\n",
    "    keyword = []\n",
    "    for result in results:\n",
    "\n",
    "        # url\n",
    "        urlfound = False\n",
    "        for l in result['bibjson'][\"link\"]:\n",
    "            if l['type'] == \"fulltext\":\n",
    "                urlfound = True\n",
    "                url.append(  l['url'].replace(\"\\n\", \"\") )\n",
    "                break\n",
    "        if not urlfound:\n",
    "            # if there no url we do not interest about the Article\n",
    "            url.append(None)\n",
    "            title.append(None)\n",
    "            doi.append(None)\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "                \n",
    "            \n",
    "        # title\n",
    "        if \"title\" in  result['bibjson']:\n",
    "            title.append( result['bibjson'][\"title\"].replace(\"\\n\", \"\") )\n",
    "        else:\n",
    "            # if there no title we do not interest about the Article\n",
    "            title.append(None)\n",
    "            doi.append(None)\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "        \n",
    "        # doi\n",
    "        founddoi = False\n",
    "        for ide in result['bibjson']['identifier']:\n",
    "            if ide[\"type\"].lower() == \"doi\":\n",
    "                founddoi = True\n",
    "                doi.append( ide['id'].replace(\"\\n\", \"\") )\n",
    "                break\n",
    "        if not founddoi:\n",
    "            doi.append(None)\n",
    "        \n",
    "        # abstract\n",
    "        if \"abstract\" in  result['bibjson']:\n",
    "            abstract.append( result['bibjson'][\"abstract\"].replace(\"\\n\", '<br>') )\n",
    "        else:\n",
    "            # if there no abstract we do not interest about the Article\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "        \n",
    "        # writer\n",
    "        writer = \"\"\n",
    "        for w in result['bibjson'][\"author\"]:\n",
    "            writer = writer + \"#\" + w['name'].replace(\"\\n\", \"\")\n",
    "            if 'affiliation' in w.keys():\n",
    "                writer = writer + \"--\" + w['affiliation'].replace(\"\\n\", \"\")\n",
    "            if 'orcid_id' in w.keys():\n",
    "                writer = writer + \"---\" + w['orcid_id'].replace(\"\\n\", \"\")          \n",
    "        writers.append(writer)\n",
    "        \n",
    "        # publishdate\n",
    "        if \"created_date\" in result.keys():\n",
    "            publishdate.append( result[\"created_date\"].replace(\"\\n\", \"\") )\n",
    "        else:\n",
    "            publishdate.append( None )\n",
    "        \n",
    "        # keywords\n",
    "        if \"keywords\" in result['bibjson']:\n",
    "            keytext = \"\"\n",
    "            for k in result['bibjson'][\"keywords\"]:\n",
    "                if re.search(\"|\", k):\n",
    "                    keytext = keytext + k.replace(\"\\n\", \"\")\n",
    "        else:\n",
    "            keyword.append( None )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'doi': doi,\n",
    "        'abstract': abstract,\n",
    "        'writer': writers,\n",
    "        'publishdate': publishdate,\n",
    "        'keyword': keyword,\n",
    "                      })\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doaj.org/api/v2/search/articles/journal%3A%22Biomedical%20Journal%22%20AND%20_exists_%3Adoi%20AND%20_exists_%3Aabstract%20%20AND%20_exists_%3A%20%22bibjson.author%22%20%20\n",
      "https://doaj.org/api/v2/search/articles/journal%3A%22African%20Journal%20of%20Emergency%20Medicine%22%20AND%20_exists_%3Adoi%20AND%20_exists_%3Aabstract%20%20AND%20_exists_%3A%20%22bibjson.author%22%20%20\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# iterate over the journals\n",
    "for idx in range(len(journals)): \n",
    "    print(\"load: \" + journals.iloc[idx]['title'] + \" Ready: \" + str(np.round(100*idx/len(journals),2))+\"%\" , end='\\r')\n",
    "    searchterm = urllib.parse.quote('journal:\"'+journals.iloc[idx]['title']+'\" AND _exists_:doi AND _exists_:abstract  AND _exists_: \"bibjson.author\"  ')\n",
    "    searchterm = 'https://doaj.org/api/v2/search/articles/'+searchterm\n",
    "    print(searchterm)\n",
    "    x = requests.get(searchterm +'?page=1&pageSize=100')\n",
    "    notfound = True\n",
    "    \n",
    "    journaldf  = pd.DataFrame({\n",
    "        'url': [],\n",
    "        'title': [],\n",
    "        'doi': [],\n",
    "        'abstract': [],\n",
    "        'writer': [],\n",
    "        'publishdate': [],\n",
    "        'keyword': [],\n",
    "        'journal_title': [],\n",
    "        'journal_eissn': [],\n",
    "        'journal_pissn': [],\n",
    "        'category': []\n",
    "                      })\n",
    "    \n",
    "    if x.status_code == 200:\n",
    "        # iterate over pages\n",
    "        jsonresult =  x.json()\n",
    "        if 'total' in jsonresult.keys() :\n",
    "            pagenumber = int(jsonresult['total']//100)+1\n",
    "            if jsonresult['total'] > 1000 :\n",
    "                print(\"Can not collect all of the Article for\", journals.iloc[idx]['title'], \"Total:\", jsonresult['total'])\n",
    "            for page in range(pagenumber):\n",
    "                if 'results' in jsonresult.keys():   \n",
    "                    thispage = findarticledata(jsonresult['results'])\n",
    "                    thispage['journal_title'] = journals.iloc[idx]['title']\n",
    "                    thispage['journal_eissn'] = journals.iloc[idx]['eissn']\n",
    "                    thispage['journal_pissn'] = journals.iloc[idx]['pissn']\n",
    "                    thispage['category'] = journals.iloc[idx]['category']\n",
    "                    \n",
    "                    journaldf = pd.concat([journaldf, thispage])                    \n",
    "                # go to othe next page\n",
    "                if jsonresult['total'] > 1 and page != pagenumber-1 :\n",
    "                    sleep(3)\n",
    "                    # go to next page\n",
    "                    x = requests.get(searchterm+\"?page=\"+str(page+2)+\"&pageSize=100\")\n",
    "                    if x.status_code == 200:\n",
    "                        jsonresult =  x.json()\n",
    "                    else:\n",
    "                        break\n",
    "                        \n",
    "    # save journaldf\n",
    "    journaldf.to_pickle('data/journal_'+journals.iloc[idx]['title'].replace(\" \", \"_\").replace(\"&\", \"and\")+\".pandas\" )    \n",
    "    sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
