{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the article list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import ui\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gedjournalarticles(start_url, journaltitle, filename ):\n",
    "    # open old file\n",
    "    olddf = pd.DataFrame({'url': [], 'journal': [] })\n",
    "    try:\n",
    "        olddf = pd.read_csv(filename, sep=\"|\")\n",
    "        print(olddf.tail())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    driver.get(start_url)\n",
    "    print(driver.current_url)\n",
    "    \n",
    "    # itterate over the journal searching to get the Article list\n",
    "    articles = []\n",
    "    def pagefind():\n",
    "        # get all of the Article on this page\n",
    "        content = driver.page_source\n",
    "        # load the page content in BeautifulSoup\n",
    "        soup = BeautifulSoup(content, features=\"lxml\")\n",
    "        # found the Article\n",
    "        for h5 in soup.find_all(\"h5\"):\n",
    "            # get link \n",
    "            for a in h5.find_all(\"a\"):        \n",
    "                articles.append(\"https://www.cambridge.org\"+a['href'])\n",
    "    \n",
    "        # find next page\n",
    "        for ulp in driver.find_elements_by_class_name('pagination'):    \n",
    "            for lis in ulp.find_elements_by_tag_name('a'):\n",
    "                if re.search('Next', lis.text):\n",
    "                    # go to the next page\n",
    "                    lis.click()\n",
    "                    sleep(2)\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    nextpage = True\n",
    "    while  nextpage:\n",
    "        nextpage = pagefind()                \n",
    "        print(driver.current_url, end='\\r')\n",
    "        \n",
    "    # filer out old articles\n",
    "    oldarticles = olddf['url']\n",
    "    articles = list( set(articles).difference(set(oldarticles) ))\n",
    "    print(len(articles), \"new article found!\")\n",
    "    \n",
    "    # make df\n",
    "    df = pd.DataFrame({'url': list(set(articles)), 'journal': journaltitle })\n",
    "    \n",
    "    return df, olddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getarticledetails(df, olddf, filename):\n",
    "    \n",
    "    articles = df['url'].values\n",
    "\n",
    "    titles = [ None for _ in range(len(df))]\n",
    "    abstracts = [ None for _ in range(len(df))]\n",
    "    writers = [ None for _ in range(len(df))]\n",
    "    dates = [ None for _ in range(len(df))]\n",
    "    dois = [  None for _ in range(len(df)) ]\n",
    "    keywords = [  None for _ in range(len(df)) ]\n",
    "\n",
    "    for idx in range(len(articles)):\n",
    "        # print percentiage of the process\n",
    "        print( str(np.round(100*idx/len(df),2))+\"%\" , end='\\r')\n",
    "    \n",
    "        url = df.iloc[idx]['url']\n",
    "        request = urllib.request.Request(url)\n",
    "        request.add_header('Accept-Encoding', 'utf-8')\n",
    "        try:\n",
    "            response = urlopen(request)    \n",
    "            page_content = response.read().decode('utf-8')\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        page_soup = BeautifulSoup(page_content, features=\"lxml\", from_encoding='utf-8')\n",
    "        \n",
    "        # abstract\n",
    "        abstract = \"\"\n",
    "        for abstdiv in page_soup.findAll(\"div\", {'class':['abstract']}):\n",
    "            for ap in abstdiv.find_all(\"p\"):\n",
    "                abstract = abstract + (\" \".join(ap.get_text().splitlines()).replace(\"\\xa0\", \" \") )\n",
    "        if len(abstract) > 0:\n",
    "            abstracts[idx] = abstract\n",
    "        else:\n",
    "            # if no abstract we ignore the page\n",
    "            continue\n",
    "\n",
    "        # title\n",
    "        for t in page_soup.find_all('title'):        \n",
    "            titles[idx] = t.get_text().split(\"|\")[0]                \n",
    "            \n",
    "        # writer and publish date\n",
    "        writter = []\n",
    "        for m in page_soup.find_all(\"meta\"):\n",
    "            if m.has_attr(\"name\"):\n",
    "                if m['name'] == \"citation_author\":\n",
    "                    writter.append( m['content'] )\n",
    "                # add the author institute to the author\n",
    "                elif m['name'] == \"citation_author_institution\":\n",
    "                    writter[-1] = writter[-1] + \"--\" + m['content']\n",
    "                # add writer orcid \n",
    "                elif m['name'] == \"citation_author_orcid\":\n",
    "                    writter[-1] = writter[-1] + \"---\" + m['content']\n",
    "                elif m['name'] == \"citation_online_date\":\n",
    "                    # change to ISO dateformat\n",
    "                    dates[idx] = datetime.datetime.strptime(m['content'], \"%Y/%m/%d\").strftime('%Y-%m-%d')\n",
    "                elif m['name'] == \"citation_doi\":\n",
    "                    dois[idx] = m['content']\n",
    "        if len(writter) > 0:\n",
    "            writers[idx] =  \"#\".join(writter)\n",
    "        \n",
    "        # keywords\n",
    "        key = []\n",
    "        for keya in page_soup.findAll(\"a\", {'class':['keywords']}):\n",
    "            key.append(keya.text)\n",
    "        if len(key) > 0:\n",
    "            keywords[idx] =  \"#\".join(key)\n",
    "    \n",
    "    # extend the df\n",
    "    df['title'] = titles\n",
    "    df['doi'] = dois\n",
    "    df['abstract'] = abstracts\n",
    "    df['writer'] = writers\n",
    "    df['publishdate'] = dates\n",
    "    df['keyword'] = keywords\n",
    "    \n",
    "    # merge owith old df\n",
    "    df = pd.concat([df, olddf])\n",
    "    \n",
    "    # save data\n",
    "    df.to_csv(filename, sep=\"|\", index=False)\n",
    "    \n",
    "    # test\n",
    "    test = pd.read_csv(filename, sep=\"|\")\n",
    "    print(test.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = ['Annals_of_Glaciology', 'Journal_of_Glaciology']\n",
    "start_urls = [ \n",
    "    \"https://www.cambridge.org/core/journals/annals-of-glaciology/listing?q=&searchWithinIds=DD7BD3FCBF82BF09609E5A0E1888ED7B&aggs[productTypes][filters]=JOURNAL_ARTICLE\",\n",
    "    \"https://www.cambridge.org/core/journals/journal-of-glaciology/listing?q=&searchWithinIds=FE8284B2577ADBCD299821FDE4E752F1&aggs[productTypes][filters]=JOURNAL_ARTICLE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    url               journal  \\\n",
      "3843  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3844  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3845  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3846  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3847  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "\n",
      "                                                  title  \\\n",
      "3843  An initial numerical investigation of the exte...   \n",
      "3844  A synthesis of remote sensing data on Wilkins ...   \n",
      "3845  AVHRR-based Polar Pathfinder products for mode...   \n",
      "3846  The potential of using Landsat 7 ETM+ for the ...   \n",
      "3847  Variability in accumulation rates from GPR pro...   \n",
      "\n",
      "                             doi  \\\n",
      "3843   10.3189/1991AoG15-1-31-36   \n",
      "3844   10.3189/S0260305500012866   \n",
      "3845   10.3189/S0260305500014336   \n",
      "3846  10.3189/172756402781817536   \n",
      "3847  10.3189/172756404781814393   \n",
      "\n",
      "                                               abstract  \\\n",
      "3843  A two-level, viscous-plastic, sea-ice model is...   \n",
      "3844  Wilkins Ice Shelf has an area of 16000 km2 and...   \n",
      "3845  A suite of Arctic and Antarctic products is be...   \n",
      "3846  During spring and summer, the surface of the A...   \n",
      "3847  Isochronal layers in firn detected with ground...   \n",
      "\n",
      "                                                 writer publishdate keyword  \n",
      "3843                 Gregory M. Flato#William D. Hibler  2017-01-20     NaN  \n",
      "3844  D.G. Vaughan#D.R. Mantripp#J. Sievers#C.S.M. D...  2017-01-20     NaN  \n",
      "3845  James Maslanik#Charles Fowler#Jeffrey Key#Ted ...  2017-01-20     NaN  \n",
      "3846  Thorsten Markus#Donald J. Cavalieri#Alvaro Iva...  2017-09-14     NaN  \n",
      "3847  Vandy B. Spikes--Climate Change Institute#Gord...  2018-06-26     NaN  \n",
      "https://www.cambridge.org/core/journals/annals-of-glaciology/listing?q=&searchWithinIds=DD7BD3FCBF82BF09609E5A0E1888ED7B&aggs[productTypes][filters]=JOURNAL_ARTICLE\n",
      "0 new article found!e.org/core/journals/annals-of-glaciology/listing?aggs%5BproductTypes%5D%5Bfilters%5D=JOURNAL_ARTICLE&pageNum=193&searchWithinIds=DD7BD3FCBF82BF09609E5A0E1888ED7B\n",
      "                                                    url               journal  \\\n",
      "3843  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3844  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3845  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3846  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "3847  https://www.cambridge.org/core/journals/annals...  Annals_of_Glaciology   \n",
      "\n",
      "                                                  title  \\\n",
      "3843  An initial numerical investigation of the exte...   \n",
      "3844  A synthesis of remote sensing data on Wilkins ...   \n",
      "3845  AVHRR-based Polar Pathfinder products for mode...   \n",
      "3846  The potential of using Landsat 7 ETM+ for the ...   \n",
      "3847  Variability in accumulation rates from GPR pro...   \n",
      "\n",
      "                             doi  \\\n",
      "3843   10.3189/1991AoG15-1-31-36   \n",
      "3844   10.3189/S0260305500012866   \n",
      "3845   10.3189/S0260305500014336   \n",
      "3846  10.3189/172756402781817536   \n",
      "3847  10.3189/172756404781814393   \n",
      "\n",
      "                                               abstract  \\\n",
      "3843  A two-level, viscous-plastic, sea-ice model is...   \n",
      "3844  Wilkins Ice Shelf has an area of 16000 km2 and...   \n",
      "3845  A suite of Arctic and Antarctic products is be...   \n",
      "3846  During spring and summer, the surface of the A...   \n",
      "3847  Isochronal layers in firn detected with ground...   \n",
      "\n",
      "                                                 writer publishdate keyword  \n",
      "3843                 Gregory M. Flato#William D. Hibler  2017-01-20     NaN  \n",
      "3844  D.G. Vaughan#D.R. Mantripp#J. Sievers#C.S.M. D...  2017-01-20     NaN  \n",
      "3845  James Maslanik#Charles Fowler#Jeffrey Key#Ted ...  2017-01-20     NaN  \n",
      "3846  Thorsten Markus#Donald J. Cavalieri#Alvaro Iva...  2017-09-14     NaN  \n",
      "3847  Vandy B. Spikes--Climate Change Institute#Gord...  2018-06-26     NaN  \n",
      "https://www.cambridge.org/core/journals/journal-of-glaciology/listing?q=&searchWithinIds=FE8284B2577ADBCD299821FDE4E752F1&aggs[productTypes][filters]=JOURNAL_ARTICLE\n",
      "5537 new article found!rg/core/journals/journal-of-glaciology/listing?aggs%5BproductTypes%5D%5Bfilters%5D=JOURNAL_ARTICLE&pageNum=277&searchWithinIds=FE8284B2577ADBCD299821FDE4E752F1\n",
      "0.0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bs4/__init__.py:220: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    url  \\\n",
      "5532  https://www.cambridge.org/core/journals/journa...   \n",
      "5533  https://www.cambridge.org/core/journals/journa...   \n",
      "5534  https://www.cambridge.org/core/journals/journa...   \n",
      "5535  https://www.cambridge.org/core/journals/journa...   \n",
      "5536  https://www.cambridge.org/core/journals/journa...   \n",
      "\n",
      "                    journal  \\\n",
      "5532  Journal_of_Glaciology   \n",
      "5533  Journal_of_Glaciology   \n",
      "5534  Journal_of_Glaciology   \n",
      "5535  Journal_of_Glaciology   \n",
      "5536  Journal_of_Glaciology   \n",
      "\n",
      "                                                  title  \\\n",
      "5532                                    Zusammenfassung   \n",
      "5533                                    Zusammenfassung   \n",
      "5534  A combined surface-and volume-scattering model...   \n",
      "5535                                    Zusammenfassung   \n",
      "5536  Spatial and temporal variations in albedo on S...   \n",
      "\n",
      "                             doi  \\\n",
      "5532   10.3189/S0022143000018931   \n",
      "5533   10.3189/S0022143000006833   \n",
      "5534   10.3189/S0022143000016579   \n",
      "5535   10.3189/S0022143000028379   \n",
      "5536  10.3189/172756503781830980   \n",
      "\n",
      "                                               abstract  \\\n",
      "5532  The earthquake of 27 March 1964 in Alaska crea...   \n",
      "5533  Subglacial hydrology is investigated for an ic...   \n",
      "5534  Over the last 15 years, satellite-altimeter da...   \n",
      "5535  Compared with freshwater ice, whose physical p...   \n",
      "5536  Extensive albedo data from Storglaci√§ren, Swed...   \n",
      "\n",
      "                                                 writer publishdate keyword  \n",
      "5532                                Lawrence E. Nielsen  2017-01-30     NaN  \n",
      "5533  E. M. Shoemaker--Department of Mathematics and...  2017-01-20     NaN  \n",
      "5534  Curt H. Davis--Electrical and Computer Enginee...  2017-01-20     NaN  \n",
      "5535       Peter Schwerdtfecer--University of Melbourne  2017-01-30     NaN  \n",
      "5536  Ulf Jonsell--Department of Physical Geography ...  2017-09-08     NaN  \n"
     ]
    }
   ],
   "source": [
    "for jidx in range(len(journals)):\n",
    "    filename = filename = 'data/journal_'+ journals[jidx] +'_'+version+'.csv'\n",
    "    \n",
    "    # search for articles\n",
    "    df, olddf = gedjournalarticles(start_urls[jidx], journals[jidx], filename )\n",
    "    \n",
    "    # get the articles details\n",
    "    getarticledetails(df, olddf, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
