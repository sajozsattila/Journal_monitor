{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Journals which we are searching for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of                                                  title  \\\n",
       "0    Database: The Journal of Biological Databases ...   \n",
       "1                                           AoB Plants   \n",
       "2                                       Burns & Trauma   \n",
       "3                              Conservation Physiology   \n",
       "4                                      Current Zoology   \n",
       "..                                                 ...   \n",
       "139              Epidemiology and Psychiatric Sciences   \n",
       "140                         Epidemiology and Infection   \n",
       "141                                       BJPsych Open   \n",
       "142                        Forum of Mathematics, Sigma   \n",
       "143                           Forum of Mathematics, Pi   \n",
       "\n",
       "                      publisher      eissn      pissn  \\\n",
       "0       Oxford University Press  1758-0463        NaN   \n",
       "1       Oxford University Press  2041-2851        NaN   \n",
       "2       Oxford University Press  2321-3876        NaN   \n",
       "3       Oxford University Press  2051-1434        NaN   \n",
       "4       Oxford University Press  2396-9814  1674-5507   \n",
       "..                          ...        ...        ...   \n",
       "139  Cambridge University Press  2045-7979  2045-7960   \n",
       "140  Cambridge University Press  1469-4409        NaN   \n",
       "141  Cambridge University Press  2056-4724        NaN   \n",
       "142  Cambridge University Press  2050-5094        NaN   \n",
       "143  Cambridge University Press  2050-5086        NaN   \n",
       "\n",
       "                               doajid  \\\n",
       "0    7130ab1e1de947e1b27bd3d8e304252d   \n",
       "1    b9d45906bda24257b4a1ac4528f42f8e   \n",
       "2    e1d8c9b3620542bbaa9623c6f61d2198   \n",
       "3    9501e32b68b64b4b8f84902b418343db   \n",
       "4    c08c46a67afd4a3bb09165920a5bd0e3   \n",
       "..                                ...   \n",
       "139  394000a0a14c48c1ad8a371057a89eba   \n",
       "140  a1f2ae4bc11f4ff59a4bd50492e97bcf   \n",
       "141  d4970d85595442289b084bfb036f8c1e   \n",
       "142  fdbdb8bd9cd94bb288ce1ec2c4265481   \n",
       "143  33d4851361894493bf8b1a9d02596c29   \n",
       "\n",
       "                                            categories language  \n",
       "0    Computer applications to medicine. Medical inf...       EN  \n",
       "1                          Plant culture#Plant ecology       EN  \n",
       "2                                             Medicine       EN  \n",
       "3    Biology (General)#General. Including nature co...       EN  \n",
       "4                                              Zoology       EN  \n",
       "..                                                 ...      ...  \n",
       "139  Neurosciences. Biological psychiatry. Neuropsy...       EN  \n",
       "140  Infectious and parasitic diseases#Public aspec...       EN  \n",
       "141                                         Psychiatry       EN  \n",
       "142                                        Mathematics       EN  \n",
       "143                                        Mathematics       EN  \n",
       "\n",
       "[144 rows x 7 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "journals = pd.read_csv('doaj_journals.csv', sep=\"|\")\n",
    "import re\n",
    "journals.tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the article details from DOAJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findjournaldata(results):\n",
    "    publisher = None\n",
    "    eissn = None\n",
    "    pissn = None\n",
    "    title = None\n",
    "    doajid = None\n",
    "    categories = None\n",
    "    language = None\n",
    "    notfound = True\n",
    "    # iterate over the result and try to find where title exactly match\n",
    "    for result in results:\n",
    "            if result['bibjson']['title'].lower().strip() == journals.iloc[idx]['title'].lower().strip():\n",
    "                notfound = False\n",
    "                publisher = result['bibjson']['publisher']['name'] \n",
    "                if 'eissn' in result['bibjson'].keys():\n",
    "                    eissn = result['bibjson']['eissn'] \n",
    "                if 'pissn' in result['bibjson'].keys():\n",
    "                    pissn = result['bibjson']['pissn'] \n",
    "\n",
    "                title = result['bibjson']['title'] \n",
    "                doajid = result['id'] \n",
    "                categories =  \"#\".join(  [ s['term'].strip() for s in result['bibjson']['subject'] ] ) \n",
    "                language = \"#\".join(  [ s.strip() for s in result['bibjson']['language'] ] ) \n",
    "                \n",
    "                break\n",
    "    return notfound, publisher, eissn, pissn, title, doajid, categories, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "from time import sleep\n",
    "\n",
    "publishers = []\n",
    "eissns = []\n",
    "pissns = []\n",
    "titles = []\n",
    "doajids = []\n",
    "categoriess = []\n",
    "languages = []\n",
    "for idx in range(len(journals)):\n",
    "    if 'doajid' not in journals.columns or journals.iloc[idx]['doajid'] is None or not isinstance(journals.iloc[idx]['doajid'], str):\n",
    "        searchterm = urllib.parse.quote('bibjson.title:\"'+journals.iloc[idx]['title']+'\"')\n",
    "        searchterm = 'https://doaj.org/api/v2/search/journals/'+searchterm\n",
    "        x = requests.get(searchterm)\n",
    "        notfound = True\n",
    "        if x.status_code == 200:\n",
    "            # iterate over pages\n",
    "            jsonresult =  x.json()\n",
    "            if 'total' in jsonresult.keys() :\n",
    "                for page in range(int(jsonresult['total'])):\n",
    "                    page = page+1\n",
    "                    if 'results' in jsonresult.keys():                \n",
    "                        notfound, publisher, eissn, pissn, title, doajid, categories, language = findjournaldata(jsonresult['results'])\n",
    "                        if not notfound:\n",
    "                            publishers.append(publisher)\n",
    "                            eissns.append(eissn)\n",
    "                            pissns.append(pissn)\n",
    "                            titles.append(title)\n",
    "                            doajids.append(doajid)\n",
    "                            categoriess.append(categories)\n",
    "                            languages.append(language)\n",
    "                            break\n",
    "                        else:\n",
    "                            if jsonresult['total'] > 1:\n",
    "                                # go to next page\n",
    "                                x = requests.get(searchterm+\"?page=\"+str(page)+\"&pageSize=10\")\n",
    "                                print(searchterm+\"?page=\"+str(page)+\"&pageSize=10\")\n",
    "                                if x.status_code == 200:\n",
    "                                    jsonresult =  x.json()\n",
    "                                else:\n",
    "                                    break\n",
    "                \n",
    "       \n",
    "        if notfound:\n",
    "            # test there is new page if yes go there        \n",
    "            print(\"Error:\", searchterm)\n",
    "            publishers.append(None)\n",
    "            eissns.append(None)\n",
    "            pissns.append(None)\n",
    "            titles.append(journals.iloc[idx]['title'])\n",
    "            doajids.append(None)\n",
    "            categoriess.append(None)\n",
    "            languages.append(None)\n",
    "        sleep(3)\n",
    "    else:\n",
    "        publishers.append(journals.iloc[idx]['publisher'])\n",
    "        eissns.append(journals.iloc[idx]['eissn'])\n",
    "        pissns.append(journals.iloc[idx]['pissn'])\n",
    "        titles.append(journals.iloc[idx]['title'])\n",
    "        doajids.append(journals.iloc[idx]['doajid'])\n",
    "        categoriess.append(journals.iloc[idx]['categories'])\n",
    "        languages.append(journals.iloc[idx]['language'])\n",
    "    \n",
    "# enrich journals\n",
    "journals['publisher'] = publishers\n",
    "journals['eissn'] = eissns\n",
    "journals['pissn'] = pissns\n",
    "journals['title'] = titles\n",
    "journals['doajid'] = doajids\n",
    "journals['categories'] = categoriess\n",
    "journals['language'] = languages\n",
    "\n",
    "journals.to_csv('doaj_journals.csv', sep=\"|\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title                publisher  \\\n",
      "0  Database: The Journal of Biological Databases ...  Oxford University Press   \n",
      "1                                         AoB Plants  Oxford University Press   \n",
      "2                                     Burns & Trauma  Oxford University Press   \n",
      "3                            Conservation Physiology  Oxford University Press   \n",
      "4                                    Current Zoology  Oxford University Press   \n",
      "\n",
      "       eissn      pissn                            doajid  \\\n",
      "0  1758-0463        NaN  7130ab1e1de947e1b27bd3d8e304252d   \n",
      "1  2041-2851        NaN  b9d45906bda24257b4a1ac4528f42f8e   \n",
      "2  2321-3876        NaN  e1d8c9b3620542bbaa9623c6f61d2198   \n",
      "3  2051-1434        NaN  9501e32b68b64b4b8f84902b418343db   \n",
      "4  2396-9814  1674-5507  c08c46a67afd4a3bb09165920a5bd0e3   \n",
      "\n",
      "                                          categories language  \n",
      "0  Computer applications to medicine. Medical inf...       EN  \n",
      "1                        Plant culture#Plant ecology       EN  \n",
      "2                                           Medicine       EN  \n",
      "3  Biology (General)#General. Including nature co...       EN  \n",
      "4                                            Zoology       EN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>eissn</th>\n",
       "      <th>pissn</th>\n",
       "      <th>doajid</th>\n",
       "      <th>categories</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Epidemiology and Psychiatric Sciences</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>2045-7979</td>\n",
       "      <td>2045-7960</td>\n",
       "      <td>394000a0a14c48c1ad8a371057a89eba</td>\n",
       "      <td>Neurosciences. Biological psychiatry. Neuropsy...</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Epidemiology and Infection</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>1469-4409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a1f2ae4bc11f4ff59a4bd50492e97bcf</td>\n",
       "      <td>Infectious and parasitic diseases#Public aspec...</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>BJPsych Open</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>2056-4724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d4970d85595442289b084bfb036f8c1e</td>\n",
       "      <td>Psychiatry</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Forum of Mathematics, Sigma</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>2050-5094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fdbdb8bd9cd94bb288ce1ec2c4265481</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Forum of Mathematics, Pi</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>2050-5086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33d4851361894493bf8b1a9d02596c29</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title                   publisher  \\\n",
       "139  Epidemiology and Psychiatric Sciences  Cambridge University Press   \n",
       "140             Epidemiology and Infection  Cambridge University Press   \n",
       "141                           BJPsych Open  Cambridge University Press   \n",
       "142            Forum of Mathematics, Sigma  Cambridge University Press   \n",
       "143               Forum of Mathematics, Pi  Cambridge University Press   \n",
       "\n",
       "         eissn      pissn                            doajid  \\\n",
       "139  2045-7979  2045-7960  394000a0a14c48c1ad8a371057a89eba   \n",
       "140  1469-4409        NaN  a1f2ae4bc11f4ff59a4bd50492e97bcf   \n",
       "141  2056-4724        NaN  d4970d85595442289b084bfb036f8c1e   \n",
       "142  2050-5094        NaN  fdbdb8bd9cd94bb288ce1ec2c4265481   \n",
       "143  2050-5086        NaN  33d4851361894493bf8b1a9d02596c29   \n",
       "\n",
       "                                            categories language  \n",
       "139  Neurosciences. Biological psychiatry. Neuropsy...       EN  \n",
       "140  Infectious and parasitic diseases#Public aspec...       EN  \n",
       "141                                         Psychiatry       EN  \n",
       "142                                        Mathematics       EN  \n",
       "143                                        Mathematics       EN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(journals.head())\n",
    "journals.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the articles for the Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findarticledata(results):\n",
    "    \n",
    "    # iterrate over Articles\n",
    "    url = []\n",
    "    title = []\n",
    "    doi = []\n",
    "    abstract  = []\n",
    "    writers = []\n",
    "    publishdate = []\n",
    "    keyword = []\n",
    "    for result in results:\n",
    "\n",
    "        # url\n",
    "        urlfound = False\n",
    "        for l in result['bibjson'][\"link\"]:\n",
    "            if l['type'] == \"fulltext\":\n",
    "                urlfound = True\n",
    "                url.append(  l['url'].replace(\"\\n\", \"\") )\n",
    "                break\n",
    "        if not urlfound:\n",
    "            # if there no url we do not interest about the Article\n",
    "            url.append(None)\n",
    "            title.append(None)\n",
    "            doi.append(None)\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "                \n",
    "            \n",
    "        # title\n",
    "        if \"title\" in  result['bibjson']:\n",
    "            title.append( result['bibjson'][\"title\"].replace(\"\\n\", \"\") )\n",
    "        else:\n",
    "            # if there no title we do not interest about the Article\n",
    "            title.append(None)\n",
    "            doi.append(None)\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "        \n",
    "        # doi\n",
    "        founddoi = False\n",
    "        for ide in result['bibjson']['identifier']:\n",
    "            if ide[\"type\"].lower() == \"doi\":\n",
    "                founddoi = True\n",
    "                doi.append( ide['id'].replace(\"\\n\", \"\") )\n",
    "                break\n",
    "        if not founddoi:\n",
    "            doi.append(None)\n",
    "        \n",
    "        # abstract\n",
    "        if \"abstract\" in  result['bibjson']:\n",
    "            abstract.append( result['bibjson'][\"abstract\"].replace(\"\\n\", '<br>') )\n",
    "        else:\n",
    "            # if there no abstract we do not interest about the Article\n",
    "            abstract.append( None )\n",
    "            writers.append(None)\n",
    "            publishdate.append( None )\n",
    "            keyword.append( None )\n",
    "            continue\n",
    "        \n",
    "        # writer\n",
    "        writer = \"\"\n",
    "        for w in result['bibjson'][\"author\"]:\n",
    "            writer = writer + \"#\" + w['name'].replace(\"\\n\", \"\")\n",
    "            if 'affiliation' in w.keys():\n",
    "                writer = writer + \"--\" + w['affiliation'].replace(\"\\n\", \"\")\n",
    "            if 'orcid_id' in w.keys():\n",
    "                writer = writer + \"---\" + w['orcid_id'].replace(\"\\n\", \"\")          \n",
    "        writers.append(writer)\n",
    "        \n",
    "        # publishdate\n",
    "        if \"created_date\" in result.keys():\n",
    "            publishdate.append( result[\"created_date\"].replace(\"\\n\", \"\") )\n",
    "        else:\n",
    "            publishdate.append( None )\n",
    "        \n",
    "        # keywords\n",
    "        # we put there a filter as if there is too much keyword the are not informatiom\n",
    "        if \"keywords\" in result['bibjson'] and len(result['bibjson'][\"keywords\"]) < 15 :\n",
    "            keytext = \"\"            \n",
    "            for k in result['bibjson'][\"keywords\"]:\n",
    "                if len(k) < 100:\n",
    "                    keytext = keytext + \"#\" + k.replace(\"\\n\", \"\")\n",
    "            if len(keytext) == 0:\n",
    "                keyword.append( None )\n",
    "            else:\n",
    "                keyword.append( keytext )\n",
    "        else:\n",
    "            keyword.append( None )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'doi': doi,\n",
    "        'abstract': abstract,\n",
    "        'writer': writers,\n",
    "        'publishdate': publishdate,\n",
    "        'keyword': keyword,\n",
    "                      })\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load: Database: The Journal of Biological Databases and Curation Ready:  0.0%\r",
      "https://doaj.org/api/v2/search/articles/journal%3A%22Database%3A%20The%20Journal%20of%20Biological%20Databases%20and%20Curation%22%20AND%20_exists_%3Adoi%20AND%20_exists_%3Aabstract%20%20AND%20_exists_%3A%20%22bibjson.author%22%20%20AND%20issn%3A%20%221758-0463%22?page=1&pageSize=100&sort=bibjson.title:desc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-707e1dea515e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# save journaldf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mjournaldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/journal_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mjournals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"and\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pandas\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# iterate over the journals\n",
    "for idx in range(len(journals)): \n",
    "    print(\"load:\", journals.iloc[idx]['title'], \"Ready: \", str(np.round(100*idx/len(journals),2))+\"%\", end='\\r')\n",
    "    searchtext = 'journal:\"'+journals.iloc[idx]['title']+'\" AND _exists_:doi AND _exists_:abstract  AND _exists_: \"bibjson.author\" '\n",
    "    # searchtext = 'journal:\"'+journals.iloc[idx]['title']+'\" AND _exists_:abstract  AND _exists_: \"bibjson.author\" '\n",
    "    # add issn\n",
    "    if isinstance(journals.iloc[idx]['eissn'], str):\n",
    "        searchtext = searchtext + ' AND issn: \"'+journals.iloc[idx]['eissn']+'\"'\n",
    "    else:\n",
    "        if isinstance(journals.iloc[idx]['pissn'], str):\n",
    "            searchtext = searchtext + ' AND issn: \"'+journals.iloc[idx]['pissn']+'\"'        \n",
    "    searchterm = urllib.parse.quote(searchtext)\n",
    "    searchterm = 'https://doaj.org/api/v2/search/articles/'+searchterm\n",
    "    print(searchterm +'?page=1&pageSize=100&sort=bibjson.title:desc')\n",
    "    x = requests.get(searchterm +'?page=1&pageSize=100&sort=bibjson.title:desc')\n",
    "    notfound = True\n",
    "    \n",
    "    journaldf  = pd.DataFrame({\n",
    "        'url': [],\n",
    "        'title': [],\n",
    "        'doi': [],\n",
    "        'abstract': [],\n",
    "        'writer': [],\n",
    "        'publishdate': [],\n",
    "        'keyword': [],\n",
    "        'journal_title': [],\n",
    "        'journal_eissn': [],\n",
    "        'journal_pissn': [],\n",
    "        'category': []\n",
    "                      })\n",
    "    \n",
    "    if x.status_code == 200:\n",
    "        # iterate over pages\n",
    "        jsonresult =  x.json()\n",
    "        if 'total' in jsonresult.keys() :\n",
    "            pagenumber = int(jsonresult['total']//100)+1\n",
    "            if jsonresult['total'] > 1000 :\n",
    "                print(\"Can not collect all of the Article for\", journals.iloc[idx]['title'], \"Total:\", jsonresult['total'])\n",
    "            for page in range(pagenumber):\n",
    "                if 'results' in jsonresult.keys():   \n",
    "                    thispage = findarticledata(jsonresult['results'])\n",
    "                    thispage['journal_title'] = journals.iloc[idx]['title']\n",
    "                    thispage['journal_eissn'] = journals.iloc[idx]['eissn']\n",
    "                    thispage['journal_pissn'] = journals.iloc[idx]['pissn']\n",
    "                    thispage['category'] = journals.iloc[idx]['categories']\n",
    "                    \n",
    "                    journaldf = pd.concat([journaldf, thispage])                    \n",
    "                # go to othe next page\n",
    "                if jsonresult['total'] > 1 and page != pagenumber-1 :\n",
    "                    sleep(3)\n",
    "                    # go to next page\n",
    "                    x = requests.get(searchterm+\"?page=\"+str(page+2)+\"&pageSize=100\")\n",
    "                    if x.status_code == 200:\n",
    "                        jsonresult =  x.json()\n",
    "                    else:\n",
    "                        break\n",
    "                        \n",
    "    # save journaldf\n",
    "    journaldf.to_pickle('data/journal_'+journals.iloc[idx]['title'].replace(\" \", \"_\").replace(\"&\", \"and\")+\".pandas\" )    \n",
    "    sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
